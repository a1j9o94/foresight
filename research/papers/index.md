# Paper Index

Master list of papers reviewed for the Foresight project.

## Status Legend

| Status | Meaning |
|--------|---------|
| `[ ]` | Not started |
| `[~]` | In progress |
| `[x]` | Complete |
| `[!]` | High priority |

## Video Generation Models

| Status | Paper | Year | Notes |
|--------|-------|------|-------|
| `[!]` | LTX-Video | 2024 | Primary video decoder candidate |
| `[!]` | HunyuanVideo | 2024 | High-quality video decoder option |
| `[ ]` | Stable Video Diffusion | 2023 | Image-to-video baseline |
| `[ ]` | Sora Technical Report | 2024 | Large-scale video generation |

## World Models

| Status | Paper | Year | Notes |
|--------|-------|------|-------|
| `[!]` | JEPA (I-JEPA, V-JEPA) | 2023-24 | Latent prediction approach |
| `[ ]` | Dreamer v3 | 2023 | Model-based RL world model |
| `[ ]` | IRIS | 2023 | Discrete world model for Atari |
| `[ ]` | Genie | 2024 | World model from video |

## Vision-Language Models

| Status | Paper | Year | Notes |
|--------|-------|------|-------|
| `[!]` | Qwen2-VL | 2024 | Our VLM backbone |
| `[ ]` | LLaVA-NeXT | 2024 | Alternative VLM |
| `[ ]` | InternVL 2 | 2024 | Strong video understanding |
| `[ ]` | Video-LLaVA | 2024 | Video-specific VLM |

## Video Understanding

| Status | Paper | Year | Notes |
|--------|-------|------|-------|
| `[ ]` | VideoChat | 2023 | Chat with videos |
| `[ ]` | Video-ChatGPT | 2023 | Video QA |
| `[ ]` | LLaVA-Video | 2024 | Long video understanding |

## Verification and Grounding

| Status | Paper | Year | Notes |
|--------|-------|------|-------|
| `[ ]` | LPIPS | 2018 | Perceptual similarity metric |
| `[ ]` | FVD | 2019 | Video quality metric |
| `[ ]` | VideoScore | 2024 | VLM-based video evaluation |

## Datasets

| Status | Paper | Year | Notes |
|--------|-------|------|-------|
| `[ ]` | COIN | 2019 | Procedural activities |
| `[ ]` | CrossTask | 2019 | Instructional videos |
| `[ ]` | Something-Something v2 | 2017 | Object interactions |

## Training Techniques

| Status | Paper | Year | Notes |
|--------|-------|------|-------|
| `[ ]` | LoRA | 2021 | Parameter-efficient fine-tuning |
| `[ ]` | QLoRA | 2023 | Quantized LoRA |
| `[ ]` | Flash Attention 2 | 2023 | Efficient attention |

---

## Recently Added

*Papers added in the last update*

(none yet)

## To Review Next

*Priority queue for paper review*

1. LTX-Video - Primary video decoder
2. Qwen2-VL - Our VLM backbone
3. V-JEPA - Latent video prediction
4. COIN dataset - Training data source
